{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/singhvis29/Hands_On_LLM_WR/blob/main/Ch3_Looking_inside_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hrwR8G6oGVD"
   },
   "source": [
    "This NB contains code used in Chapter 3 - Looking inside LLMs of the book 'Hands-On Large Language Models' book by Jay Alammar and Maarten Grootendorst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0yj4Oqznqvaq"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mzuWBPaHofmI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753,
     "referenced_widgets": [
      "8f064306f05c4945897dea113256aabb",
      "c53fe3951f1b4712a43719f883574a0d",
      "5a23f7cc23e949f1a61d6f7c88101866",
      "61ee2d59b3794e1ea1c1c9b0e341bf8b",
      "6f6f970e8e46470786be67dce46d23d5",
      "82d6febf022145a59586a8c202cd53ae",
      "2aef6c73e96044a8b4c4e6c676b182d4",
      "64057eae39614ff8abd26d3c3c1f1aa3",
      "639a642e1029448f8ac61718cd540ffd",
      "e3d42ebc6b9e4ea7bcd7158485994474",
      "a9319e71568d4753b64196132ac045c7",
      "4ad3d52a7be247ca9584af73cac0d856",
      "c3cc921ebbf14cb6a8b2c29607f14a92",
      "ab061f75c2ff4fb9bdd0a17391fce91b",
      "4a82885bd03e40279f4d82f029fbe98a",
      "09bdba7f1f7543369e670aedbd1802d4",
      "006c31c8960747eeb98155069f0b6d80",
      "789d1821ae054e5c90f16312e7415b52",
      "a9953e1067284cb69755125c888cf9b3",
      "223b3bd5ccb64b3fb5481f2f8b41409b",
      "4b19e0693fa6415f90a86ce600ba609b",
      "ca1c2ad99e274b75ba6b011654ef4298",
      "952196d9777a46fe92749a575db7bc58",
      "915f4283b2f44897bb41a7b913962429",
      "3684aff8204743698b55d1d0693056bc",
      "7d745fe7652447989b4422dd7a2a6009",
      "d16b7fb2cd7f49bb91a3d0bb820d314d",
      "bc99d76e5d364106bfb3545f3778163d",
      "894943b894d4412bbe4bb7e0a9d664c8",
      "d163efacae0f48bb992a5217daf84665",
      "638785d449694de2b644c190b28f65f7",
      "0f74c84ae5bf44419a18fd6f9172f411",
      "522dbe72e7824da58aa3778c0557df79",
      "d82d173d08bf4c47b1ab51945427de48",
      "978db649cb0f402a940ab44646565832",
      "d2ffb3c3f5d14e50bd814e78b3118739",
      "9a66d85fbc6545f8bb088075ae6a7a6b",
      "60ffa9f5ab1b4c6486ca2570b45b7c99",
      "3bdffaa593b14efc9072304d69396a6c",
      "5712d0871e2c4d8fbb004c25ffeab977",
      "b19c56ac141c4e3397e4f999b5071aea",
      "a27e9113503e41c1abe7fbef33fc74a4",
      "fe6ea8264af245adb39ba6f14081075b",
      "fc556cc3213c4bfa8f8a82ee1f0d4a5d",
      "110ac93fd8ca42e78c3253d71c274eaf",
      "b32b089b444c46b48d75acffad813ddb",
      "c8d56003b5dd4b0ea4d27aea3d77f826",
      "14d64957ffec49bda7533a5cb38e7bfa",
      "ad756e3fb2ea4241a8e8f4d6cb596182",
      "271dadb1e28846428b03bf4a46cf6601",
      "bc99c786771a4f6783041ae6f584b6aa",
      "c5228d7934854b7f9916911b0e7652ac",
      "3cc5b14756c04f02a801d88cc8eee3c0",
      "9e51eeb923684592aedb118ac7046458",
      "4bd9978dd2384fa39b0f41aa5a2cf67e",
      "16c61e656fd74cc3b36368886ce55328",
      "d9321e20603b455cab5e1c83daf77b55",
      "143c02be717d4b5699d86bd3a366109c",
      "17c0a5bb90fb481da42b9cc8a6d5de03",
      "b510c665d49c48c5b2079089f8d29e60",
      "b0bc2584501c4dec865d4e1e6f1641ff",
      "ca75cf04c5e5445dac9f7f96123d1543",
      "2ff4394ac18f43d1be57cdffc1114875",
      "dbb56dbfead9400c96f434afcba3fbbf",
      "9ca6d63f2cac4046b46b7b023807cb21",
      "581de16d1e6c4a3e8a61d35170c9d2f6",
      "8a175b9f78aa42aab80614274a072285",
      "0799f1dbded349be81d9e7ef71d1c257",
      "918e116a372c4db092a260ef52d01748",
      "ec79b75daca04c6d9af14e191d4172a8",
      "341fc130184440148d45c4c9a57b4d4c",
      "88c44d19f95d4662b61f026b2dcceab3",
      "66a74e28850c480fa40f6f094186f38b",
      "93c822bdf63845759a584a21222b4776",
      "41d8f89a674644e4b377bb22f40c82a0",
      "5ab69ed8215b414e9acfab0ad2029ea8",
      "1ffe01a54e934375bc489dfd9c748ece",
      "33d3999d3f8d4c2c998000df5e0d5fe1",
      "24e64e826e284ec0852ecf8b71556192",
      "8a601960bead4a97a8ce5aaa1d70cb11",
      "df75597e7a30490983c888057ad8f081",
      "e5b1bac7e25a48f89e037c06a0f20958",
      "95f499b1fe8b47f58ca8fb219029e055",
      "e8a1673964f14cdeba6f7a8bee16540f",
      "60b8d05a6c064dd4841f9fe298985a8e",
      "d306a3d1d0004a64901c41b2b17eeb31",
      "d53d9c3c0774425589508b07c380571f",
      "a80ce7606d194e16953a75b3cb052e10",
      "0611018ddee943318836ad9784d5f173",
      "8c1cd7b3c70740edb606d491db107cb6",
      "4ff2ba71231f4d98a5c662f81c3daecb",
      "f2ef32fb7b2440e78dd96981d144481d",
      "cb6c4ef7615e4237bb2c469d88e5e7b7",
      "8c8bff06103c4c68bab143e47cab6de6",
      "b2ab528d20454286a27dc69786126432",
      "62030618d30a4aa59d867604be014c10",
      "7e5c7dad551a45ac97a68e94a66fa897",
      "3d418aef36f24e7481a499436eb19e9a",
      "e28e9dba4db2404bb94376c69cd2c71b",
      "b1d188e86ae34114828fdb991f5fdb07",
      "ef67dde7beec47edb0b636504cf07f56",
      "aeedb9d851294d629af0202b6f320693",
      "79cf79e47fb040708d145cfb933fa5b1",
      "e473d71039c84e72b7d90a89615f0ab0",
      "550593581ccc4b31b1d43ab70e609a8d",
      "ca11ead03b0e4b79b451113d1376f911",
      "25f6f68ebf1446c28d9001a5560d0528",
      "0e8891ab887a4e12b6f756b096111bc2",
      "3ad5a208d3a84ef0a13d6be02dd3cf80",
      "8481068cf152467abeebe04685224ff9",
      "a721f29a90f34948a14b761c0abd0f13",
      "4a3f2b0fdbbc4f41a02f44d39050958e",
      "0cbca9eb7f124ebf8a5a2ee9cc2645e5",
      "feac2a571797417384fc87b716f1cb79",
      "ab011fd15eab4701916e16328a4eaf98",
      "fa82c1a36f494eabaa7f8893daef7fd6",
      "13fa3c7a8ced4a82bbf556b177cbf8d9",
      "6877acd177ce485abe6ebe68ab561df6",
      "fb3a10c13bde4009bbde581ffbaedb72",
      "49a8ecc5505044f2a86f263d95d2e805",
      "a3e8d688e8044dc587b84aaa1f1acab7",
      "0f47dbb392c3496489390c3e3de4c99c",
      "970b7def47ee4da2ac7a0a042486c5e2",
      "822db1ac44114db69e9a7bd9fbb52c86",
      "04822c8ee05a496a87ed497e3dfa101a",
      "d3549130b99e4eb28ecfa8a886f61920",
      "cf2f60e4fecf48689a1167c74025808f",
      "f7cd1278fd544e3f91e27ff6f3cbf20c",
      "3bfd154054ee41a285b5be76983c590c",
      "06a581aa03a149498810b0cd61024489",
      "b819710b912e48c9ac63684dfe18fda5",
      "281bda48e6044628bc413805af5288c3",
      "869884f8f3e24e4a9e63464b05969911",
      "34a544f055c24eec960f1e612e561e61",
      "5dccd6cca364462b86492bc797a95a76",
      "999858d4799b48e7908a01996ab4f11c",
      "40bf372fd4c24be79da4b8e54f62bff6",
      "82cbdcb0e1944658a21a8eacf9f2245a",
      "f72c8c22f1c549b09eb830f57de5ab11",
      "90697794f9c248a7913fd549ba5ab3a6",
      "84c6bef4c69e40a1acd9ce2bd70c3071",
      "0bcb085ed3fc4b08aaeb7f4d2b4d616c",
      "69407e7bc8104c1ba681f4f5f6679424",
      "461cfcc37d8b4c84bf6d4213c128c5dd",
      "0031840c50cb4a7db19b69ab14ecc49e",
      "f4ee775510b341b3a180fa7e42eb556c",
      "061a57b5720848f1a3bd7a7bc16fbf6d",
      "c978635aad014512b77f5bf1974e5855",
      "3af183a543184ce5b31c89c5f01a04ea",
      "0f4d4a6aeb1f4b788413c2b9230ef101",
      "2bd173b3fd1246939fecc4f962083b51",
      "3a8372ca8efc4d5582acd33da75a2fd2",
      "f373910ecdba4a79bc1265b7a3b14707",
      "2d26f7a6fb3d43d6b510f2fc288a8c0e"
     ]
    },
    "id": "j9fNMwMqnjyI",
    "outputId": "05c6bdf1-1189-4182-abed-1b07bf4a925f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f064306f05c4945897dea113256aabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad3d52a7be247ca9584af73cac0d856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952196d9777a46fe92749a575db7bc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82d173d08bf4c47b1ab51945427de48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110ac93fd8ca42e78c3253d71c274eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c61e656fd74cc3b36368886ce55328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a175b9f78aa42aab80614274a072285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d3999d3f8d4c2c998000df5e0d5fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0611018ddee943318836ad9784d5f173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d188e86ae34114828fdb991f5fdb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a721f29a90f34948a14b761c0abd0f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f47dbb392c3496489390c3e3de4c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869884f8f3e24e4a9e63464b05969911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461cfcc37d8b4c84bf6d4213c128c5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwS7dI11p15d",
    "outputId": "92df09cd-bfba-45e8-b71b-0d265816f60a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kGDsacEUoyjh",
    "outputId": "706bffbf-8a95-4a3c-9c35-2c86a7231357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mention the steps you're taking to prevent it in the future.\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "I hope this message finds you well. I am writing to express my deepest apologies for the unfortunate incident that occurred in your garden. It was a tragic mishap that I never intended, and I am truly sorry for any distress it may have caused you.\n",
      "\n",
      "The incident happened when I was attempting to help you with your gardening project. I\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write an email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.\"\n",
    "\n",
    "output = generator(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4olpEOsxZNP",
    "outputId": "2f4d5047-7426-4af4-c42f-66cf84f7eee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \" Mention the steps you're taking to prevent it in the future.\\n\\nDear Sarah,\\n\\nI hope this message finds you well. I am writing to express my deepest apologies for the unfortunate incident that occurred in your garden. It was a tragic mishap that I never intended, and I am truly sorry for any distress it may have caused you.\\n\\nThe incident happened when I was attempting to help you with your gardening project. I\"}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPna2DIppuvn",
    "outputId": "0130f80f-f1d9-4798-aa02-4edd713c3294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phi3ForCausalLM(\n",
      "  (model): Phi3Model(\n",
      "    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x Phi3DecoderLayer(\n",
      "        (self_attn): Phi3Attention(\n",
      "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
      "          (qkv_proj): Linear(in_features=3072, out_features=9216, bias=False)\n",
      "          (rotary_emb): Phi3RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Phi3MLP(\n",
      "          (gate_up_proj): Linear(in_features=3072, out_features=16384, bias=False)\n",
      "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
      "          (activation_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): Phi3RMSNorm()\n",
      "        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (post_attention_layernorm): Phi3RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): Phi3RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5dML210qZJU"
   },
   "source": [
    "### Choosing a Single Token from the Probability Distribution (Sampling/ Decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OVjNyv9RqGt_"
   },
   "outputs": [],
   "source": [
    "prompt = \"The capital of USA is\"\n",
    "\n",
    "# Tokenize the input prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Tokenize the input prompt\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "\n",
    "# Get the output of the model before the lm_head\n",
    "model_output = model.model(input_ids)\n",
    "\n",
    "# Get the output of the lm_head\n",
    "lm_head_output = model.lm_head(model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goimk9tpqlA8",
    "outputId": "bec23cab-e8f1-4c3d-bb37-fcc703010623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 450, 7483,  310, 8278,  338]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "G1cpr2_1qmLv",
    "outputId": "0da38e70-3b21-4611-9936-34fc1f91d4bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 3072])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvT9BBoftXlS",
    "outputId": "eb2b9d64-d5f1-4d1d-f934-eb9293cc4de3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[24.7500, 24.8750, 22.7500,  ..., 19.0000, 19.0000, 19.0000],\n",
       "         [31.1250, 31.5000, 26.0000,  ..., 26.0000, 26.0000, 26.0000],\n",
       "         [31.5000, 28.8750, 31.1250,  ..., 26.2500, 26.2500, 26.2500],\n",
       "         [33.5000, 34.2500, 36.7500,  ..., 29.2500, 29.2500, 29.2500],\n",
       "         [32.7500, 33.7500, 33.7500,  ..., 25.6250, 25.6250, 25.6250]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zk5rpYxrqnnI",
    "outputId": "2c22c7b4-8a27-4b74-c966-49f4e808096d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 32064])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mg3y3dMWs-iS",
    "outputId": "d65f6b6a-5561-4f92-ce29-0c40b6b37404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32064])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_head_output[0,-1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jFcIJ3_yrNjS",
    "outputId": "c6ed02c1-65ff-471d-d6b4-4af1e1b57f0a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Washington'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = lm_head_output[0,-1].argmax(-1)\n",
    "tokenizer.decode(token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AxOCu29twPTC"
   },
   "source": [
    "### Speeding up generation by caching keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "--5xb1g8rSfk"
   },
   "outputs": [],
   "source": [
    "prompt = \"Write a very long email apologizing to Sarah for the tragic gardening mishap. Explain how it happened.\"\n",
    "\n",
    "# Tokenize the input prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids = input_ids.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mw-lOkIbwS3R",
    "outputId": "21ad0f55-a8b6-460e-8199-5d2427932b2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.12 s ± 1.92 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "# Generate the text\n",
    "generation_output = model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=100,\n",
    "  use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwLOjTxPwa78",
    "outputId": "59f78e75-3753-4cf5-d2ae-69c1fc24ee7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 s ± 207 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1\n",
    "# Generate the text\n",
    "generation_output = model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=100,\n",
    "  use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "8-Bx2UWJwhkh"
   },
   "outputs": [],
   "source": [
    "prompt = \"The Shawshank\"\n",
    "\n",
    "# Tokenize the input prompt\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Tokenize the input prompt\n",
    "input_ids = input_ids.to(\"cuda\")\n",
    "\n",
    "# Get the output of the model before the lm_head\n",
    "model_output = model.model(input_ids)\n",
    "\n",
    "# Get the output of the lm_head\n",
    "lm_head_output = model.lm_head(model_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NeO5HpYZx0Fw",
    "outputId": "036190ff-c9eb-467f-9170-0ba9a7ce0f80"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Red'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id = lm_head_output[0,-1].argmax(-1)\n",
    "tokenizer.decode(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kkhwx_RxUP0",
    "outputId": "198f9aaa-3d59-43cf-f5ce-d868cdd9de1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Redemption\n",
      "\n",
      "The Shawshank Redemption is a 1994 American drama film directed by Frank Darabont, based on the 1982 Stephen King novella Rita Hayworth and Shawshank Redemption. The film stars Tim Robbins as Andy Dufresne, a banker who is wrongly convicted of the murder of his wife and her lover, and serves a life sentence at Shawshank State Penitenti\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The Shawshank\"\n",
    "\n",
    "output = generator(prompt)\n",
    "\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oFsgvQ85xjON"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPNxvz0iMh8T/H3YhI1c0M1",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
